{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEeNT3z0F9KbyLHm0Xr21F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/110805/Spelling_Correction/blob/master/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CppjJIYuqKO",
        "colab_type": "code",
        "outputId": "333e6d57-5943-4dad-ba00-d5d0c4d7c5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/110805/Spelling_Correction.git\n",
        "%cd Spelling_Correction/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Spelling_Correction'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 59 (delta 2), reused 9 (delta 2), pack-reused 50\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n",
            "/content/Spelling_Correction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn-1wK13vV65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "141b620e-6d04-4a48-a590-b5ee91a71a62"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "from os import system\n",
        "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"========================================================================================\n",
        "The sample.py includes the following template functions:\n",
        "\n",
        "1. Encoder, decoder\n",
        "2. Training function\n",
        "3. BLEU-4 score function\n",
        "\n",
        "You have to modify them to complete the lab.\n",
        "In addition, there are still other functions that you have to \n",
        "implement by yourself.\n",
        "\n",
        "1. Your own dataloader (design in your own way, not necessary Pytorch Dataloader)\n",
        "2. Output your results (BLEU-4 score, correction words)\n",
        "3. Plot loss/score\n",
        "4. Load/save weights\n",
        "========================================================================================\"\"\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "#----------Hyper Parameters----------#\n",
        "hidden_size = 256\n",
        "vocab_size = 28\n",
        "teacher_forcing_ratio = 0.7\n",
        "LR = 0.05\n",
        "MAX_LENGTH = 20\n",
        "\n",
        "################################\n",
        "#Example inputs of compute_bleu\n",
        "################################\n",
        "#The target word\n",
        "reference = 'variable'\n",
        "#The word generated by your model\n",
        "output = 'varable'\n",
        "\n",
        "#compute BLEU-4 score\n",
        "def compute_bleu(output, reference):\n",
        "    cc = SmoothingFunction()\n",
        "    if len(reference) == 3:\n",
        "        weights = (0.33,0.33,0.33)\n",
        "    else:\n",
        "        weights = (0.25,0.25,0.25,0.25)\n",
        "    return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "def sample_pair(i, Data):\n",
        "    input_tensor = []\n",
        "    target_tensor = []\n",
        "    \n",
        "    for input_char in Data[i][0]:\n",
        "        input_tensor.append(ord(input_char)-95)\n",
        "    \n",
        "    for target_char in Data[i][1]:\n",
        "        target_tensor.append(ord(target_char)-95)\n",
        "\n",
        "    target_tensor.append(EOS_token)\n",
        "    return (torch.tensor(input_tensor, dtype=torch.long).view(-1, 1), torch.tensor(target_tensor, dtype=torch.long).view(-1, 1))\n",
        "\n",
        "#Encoder\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.lstm(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return (torch.zeros(1, 1, self.hidden_size, device=device), torch.zeros(1, 1, self.hidden_size, device=device))\n",
        "\n",
        "#Decoder\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.lstm(output, hidden)\n",
        "        output = self.out(output[0])\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    #----------sequence to sequence part for encoder----------#\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\t\n",
        "    #----------sequence to sequence part for decoder----------#\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "def evaluate(encoder, decoder, input_string, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = []\n",
        "        for input_char in input_string:\n",
        "            input_tensor.append(ord(input_char)-95)\n",
        "\n",
        "        input_tensor = torch.tensor(input_tensor, dtype=torch.long).view(-1, 1)\n",
        "    \n",
        "        input_tensor = input_tensor.to(device)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoded_words = []\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(chr(topi.item()+95))\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        pred = ''\n",
        "        for i in range(len(decoded_words)):\n",
        "            pred += decoded_words[i]\n",
        "\n",
        "        return pred\n",
        "\n",
        "def evalTestdata(encoder, decoder):\n",
        "    score = 0\n",
        "    with open('test.json') as f:\n",
        "        voc = json.load(f)\n",
        "    \n",
        "    for data in voc:\n",
        "        output = evaluate(encoder, decoder, data['input'][0])\n",
        "        #print('input: {}'.format(data['input'][0]))\n",
        "        #print('target: {}'.format(data['target']))\n",
        "        #print('pred: {}'.format(output))\n",
        "        \n",
        "        if len(output) != 0:\n",
        "            score += compute_bleu(output, data['target'])\n",
        "        else:\n",
        "            score += compute_bleu('', data['target']) # predict empty string\n",
        "        \n",
        "        #print('--------------------')\n",
        "    #print('BLEU-4 score:{}'.format(score/50))\n",
        "    return score/50\n",
        "    \n",
        "def trainIters(encoder, decoder, n_epochs, learning_rate=LR):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    BLEU_scores = []\n",
        "    epoch_loss = 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    Data = []\n",
        "    with open('train.json') as f:\n",
        "        Voc = json.load(f)\n",
        "\n",
        "    for voc in Voc:\n",
        "        for i in range(len(voc['input'])):\n",
        "            group = []\n",
        "            group.append(voc['input'][i])\n",
        "            group.append(voc['target'])\n",
        "            Data.append(group)\n",
        "\n",
        "    training_pairs = [sample_pair(i, Data) for i in range(len(Data))]\n",
        "    print('Finish sampling')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        for iter in range(len(Data)):\n",
        "            training_pair = training_pairs[iter]\n",
        "            input_tensor = training_pair[0]\n",
        "            target_tensor = training_pair[1]\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target_tensor = target_tensor.to(device)\n",
        "\n",
        "            loss = train(input_tensor, target_tensor, encoder,\n",
        "                        decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        \n",
        "            epoch_loss += loss\n",
        "\n",
        "        epoch_loss_avg = epoch_loss / len(Data) \n",
        "        plot_losses.append(epoch_loss_avg)\n",
        "        epoch_loss = 0\n",
        "        bleu_score = evalTestdata(encoder, decoder)\n",
        "        BLEU_scores.append(bleu_score)\n",
        "        print('%s (%d %d%%) %.4f %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, epoch_loss_avg, bleu_score))\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.plot(range(n_epochs), plot_losses)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('CrossEntropyLoss')\n",
        "    plt.savefig('TrainingLoss')\n",
        "\n",
        "    plt.figure(2)\n",
        "    plt.plot(range(n_epochs), BLEU_scores)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('BLEU_scores')\n",
        "    plt.savefig('BLEU_scores')\n",
        "\n",
        "encoder1 = EncoderRNN(vocab_size, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, vocab_size).to(device)\n",
        "trainIters(encoder1, decoder1, 60)\n",
        "torch.save(encoder1.state_dict(), 'encoder.pkl')\n",
        "torch.save(decoder1.state_dict(), 'decoder.pkl')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish sampling\n",
            "2m 40s (- 158m 1s) (1 1%) 1.1895 0.1094\n",
            "5m 22s (- 155m 46s) (2 3%) 1.0853 0.1319\n",
            "8m 4s (- 153m 18s) (3 5%) 1.0086 0.1784\n",
            "10m 43s (- 150m 13s) (4 6%) 0.9362 0.1698\n",
            "13m 22s (- 147m 12s) (5 8%) 0.8660 0.1957\n",
            "16m 1s (- 144m 15s) (6 10%) 0.8114 0.2016\n",
            "18m 40s (- 141m 23s) (7 11%) 0.7583 0.2693\n",
            "21m 20s (- 138m 41s) (8 13%) 0.7068 0.3138\n",
            "23m 59s (- 135m 56s) (9 15%) 0.6759 0.2711\n",
            "26m 39s (- 133m 15s) (10 16%) 0.6429 0.3219\n",
            "29m 18s (- 130m 33s) (11 18%) 0.6070 0.3510\n",
            "31m 57s (- 127m 50s) (12 20%) 0.5904 0.3797\n",
            "34m 37s (- 125m 10s) (13 21%) 0.5646 0.3312\n",
            "37m 17s (- 122m 30s) (14 23%) 0.5456 0.3769\n",
            "39m 57s (- 119m 51s) (15 25%) 0.5245 0.3861\n",
            "42m 37s (- 117m 12s) (16 26%) 0.5199 0.3821\n",
            "45m 18s (- 114m 35s) (17 28%) 0.5098 0.4182\n",
            "47m 59s (- 111m 58s) (18 30%) 0.4997 0.4271\n",
            "50m 43s (- 109m 27s) (19 31%) 0.4856 0.4163\n",
            "53m 26s (- 106m 53s) (20 33%) 0.4847 0.4383\n",
            "56m 8s (- 104m 15s) (21 35%) 0.4595 0.4473\n",
            "58m 49s (- 101m 36s) (22 36%) 0.4455 0.4000\n",
            "61m 29s (- 98m 55s) (23 38%) 0.4387 0.4991\n",
            "64m 9s (- 96m 13s) (24 40%) 0.4249 0.4819\n",
            "66m 46s (- 93m 29s) (25 41%) 0.4146 0.4726\n",
            "69m 24s (- 90m 45s) (26 43%) 0.4098 0.4140\n",
            "72m 1s (- 88m 2s) (27 45%) 0.4247 0.4855\n",
            "74m 39s (- 85m 19s) (28 46%) 0.4269 0.4777\n",
            "77m 18s (- 82m 38s) (29 48%) 0.4125 0.5326\n",
            "79m 55s (- 79m 55s) (30 50%) 0.3924 0.4525\n",
            "82m 30s (- 77m 11s) (31 51%) 0.3786 0.4626\n",
            "85m 6s (- 74m 27s) (32 53%) 0.3734 0.4994\n",
            "87m 41s (- 71m 44s) (33 55%) 0.3778 0.4781\n",
            "90m 16s (- 69m 1s) (34 56%) 0.4309 0.5716\n",
            "92m 50s (- 66m 19s) (35 58%) 0.4211 0.5136\n",
            "95m 25s (- 63m 37s) (36 60%) 0.4110 0.4816\n",
            "97m 59s (- 60m 55s) (37 61%) 0.3806 0.5434\n",
            "100m 34s (- 58m 13s) (38 63%) 0.3966 0.5981\n",
            "103m 8s (- 55m 32s) (39 65%) 0.3841 0.5691\n",
            "105m 43s (- 52m 51s) (40 66%) 0.3770 0.5089\n",
            "108m 17s (- 50m 11s) (41 68%) 0.3779 0.5476\n",
            "110m 53s (- 47m 31s) (42 70%) 0.3769 0.5114\n",
            "113m 28s (- 44m 51s) (43 71%) 0.3681 0.5123\n",
            "116m 3s (- 42m 12s) (44 73%) 0.3625 0.5106\n",
            "118m 38s (- 39m 32s) (45 75%) 0.3423 0.5530\n",
            "121m 13s (- 36m 53s) (46 76%) 0.3471 0.6441\n",
            "123m 47s (- 34m 14s) (47 78%) 0.3385 0.5671\n",
            "126m 22s (- 31m 35s) (48 80%) 0.3462 0.4514\n",
            "128m 58s (- 28m 57s) (49 81%) 0.3657 0.5224\n",
            "131m 33s (- 26m 18s) (50 83%) 0.4040 0.5400\n",
            "134m 8s (- 23m 40s) (51 85%) 0.3827 0.5685\n",
            "136m 43s (- 21m 2s) (52 86%) 0.3771 0.6081\n",
            "139m 18s (- 18m 24s) (53 88%) 0.3525 0.5482\n",
            "141m 53s (- 15m 45s) (54 90%) 0.3526 0.5566\n",
            "144m 29s (- 13m 8s) (55 91%) 0.3532 0.5637\n",
            "147m 4s (- 10m 30s) (56 93%) 0.3454 0.5523\n",
            "149m 39s (- 7m 52s) (57 95%) 0.3798 0.5114\n",
            "152m 13s (- 5m 14s) (58 96%) 0.4946 0.5285\n",
            "154m 47s (- 2m 37s) (59 98%) 0.4558 0.5718\n",
            "157m 21s (- 0m 0s) (60 100%) 0.4282 0.6146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTDHy0IvkPTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "32ac2976-589c-42a0-f1eb-8c01b25657cb"
      },
      "source": [
        "encoder = EncoderRNN(vocab_size, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, vocab_size).to(device)\n",
        "encoder.load_state_dict(torch.load('encoder.pkl'))\n",
        "decoder.load_state_dict(torch.load('decoder.pkl'))\n",
        "\n",
        "def evaluate(encoder, decoder, input_string, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = []\n",
        "        for input_char in input_string:\n",
        "            input_tensor.append(ord(input_char)-95)\n",
        "\n",
        "        input_tensor = torch.tensor(input_tensor, dtype=torch.long).view(-1, 1)\n",
        "    \n",
        "        input_tensor = input_tensor.to(device)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoded_words = []\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(chr(topi.item()+95))\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        pred = ''\n",
        "        for i in range(len(decoded_words)):\n",
        "            pred += decoded_words[i]\n",
        "\n",
        "        return pred\n",
        "\n",
        "def evalTestdata(encoder, decoder):\n",
        "    score = 0\n",
        "    with open('new_test.json') as f:\n",
        "        voc = json.load(f)\n",
        "    \n",
        "    for data in voc:\n",
        "        output = evaluate(encoder, decoder, data['input'][0])\n",
        "        print('input: {}'.format(data['input'][0]))\n",
        "        print('target: {}'.format(data['target']))\n",
        "        print('pred: {}'.format(output))\n",
        "        \n",
        "        if len(output) != 0:\n",
        "            score += compute_bleu(output, data['target'])\n",
        "        else:\n",
        "            score += compute_bleu('', data['target']) # predict empty string\n",
        "        \n",
        "        print('--------------------')\n",
        "    print('BLEU-4 score:{}'.format(score/50))\n",
        "\n",
        "evalTestdata(encoder, decoder)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: apreciate\n",
            "target: appreciate\n",
            "pred: sapaatiee\n",
            "--------------------\n",
            "input: appeciate\n",
            "target: appreciate\n",
            "pred: paypect\n",
            "--------------------\n",
            "input: apprciate\n",
            "target: appreciate\n",
            "pred: surpatite\n",
            "--------------------\n",
            "input: apprecate\n",
            "target: appreciate\n",
            "pred: superact\n",
            "--------------------\n",
            "input: apprecite\n",
            "target: appreciate\n",
            "pred: perpetiet\n",
            "--------------------\n",
            "input: luve\n",
            "target: love\n",
            "pred: luce\n",
            "--------------------\n",
            "input: culd\n",
            "target: cold\n",
            "pred: clered\n",
            "--------------------\n",
            "input: heart\n",
            "target: heart\n",
            "pred: hert\n",
            "--------------------\n",
            "input: televiseon\n",
            "target: television\n",
            "pred: television\n",
            "--------------------\n",
            "input: thone\n",
            "target: phone\n",
            "pred: phone\n",
            "--------------------\n",
            "input: phace\n",
            "target: phase\n",
            "pred: phat\n",
            "--------------------\n",
            "input: poam\n",
            "target: poem\n",
            "pred: pome\n",
            "--------------------\n",
            "input: tomorraw\n",
            "target: tomorrow\n",
            "pred: torrmarra\n",
            "--------------------\n",
            "input: presishan\n",
            "target: precision\n",
            "pred: presitan\n",
            "--------------------\n",
            "input: presishion\n",
            "target: precision\n",
            "pred: pression\n",
            "--------------------\n",
            "input: presisian\n",
            "target: precision\n",
            "pred: pressina\n",
            "--------------------\n",
            "input: presistion\n",
            "target: precision\n",
            "pred: prestinnan\n",
            "--------------------\n",
            "input: perver\n",
            "target: prefer\n",
            "pred: perver\n",
            "--------------------\n",
            "input: predgudice\n",
            "target: prejudice\n",
            "pred: predectice\n",
            "--------------------\n",
            "input: predgudis\n",
            "target: prejudice\n",
            "pred: prediers\n",
            "--------------------\n",
            "input: recievor\n",
            "target: receiver\n",
            "pred: recorve\n",
            "--------------------\n",
            "input: reciover\n",
            "target: receiver\n",
            "pred: recorrie\n",
            "--------------------\n",
            "input: relieve\n",
            "target: relief\n",
            "pred: relieve\n",
            "--------------------\n",
            "input: togather\n",
            "target: together\n",
            "pred: towather\n",
            "--------------------\n",
            "input: remuttance\n",
            "target: remittance\n",
            "pred: retemntance\n",
            "--------------------\n",
            "input: deposite\n",
            "target: deposit\n",
            "pred: doposit\n",
            "--------------------\n",
            "input: deposittt\n",
            "target: deposit\n",
            "pred: notecipt\n",
            "--------------------\n",
            "input: peper\n",
            "target: pepper\n",
            "pred: peper\n",
            "--------------------\n",
            "input: pepperrr\n",
            "target: pepper\n",
            "pred: peppear\n",
            "--------------------\n",
            "input: employe\n",
            "target: employee\n",
            "pred: poemple\n",
            "--------------------\n",
            "input: employezz\n",
            "target: employee\n",
            "pred: pemixemb\n",
            "--------------------\n",
            "input: beest\n",
            "target: best\n",
            "pred: beiest\n",
            "--------------------\n",
            "input: bestt\n",
            "target: best\n",
            "pred: patb\n",
            "--------------------\n",
            "input: aset\n",
            "target: best\n",
            "pred: esst\n",
            "--------------------\n",
            "input: feeture\n",
            "target: feature\n",
            "pred: feature\n",
            "--------------------\n",
            "input: faeture\n",
            "target: feature\n",
            "pred: fetera\n",
            "--------------------\n",
            "input: featture\n",
            "target: feature\n",
            "pred: featier\n",
            "--------------------\n",
            "input: gorges\n",
            "target: gorgeous\n",
            "pred: gorges\n",
            "--------------------\n",
            "input: gorgeus\n",
            "target: gorgeous\n",
            "pred: gordgeus\n",
            "--------------------\n",
            "input: gourgace\n",
            "target: gorgeous\n",
            "pred: guragrape\n",
            "--------------------\n",
            "input: gripe\n",
            "target: grip\n",
            "pred: srip\n",
            "--------------------\n",
            "input: hienous\n",
            "target: heinous\n",
            "pred: himnous\n",
            "--------------------\n",
            "input: hurple\n",
            "target: purple\n",
            "pred: hurpel\n",
            "--------------------\n",
            "input: occassional\n",
            "target: occasional\n",
            "pred: occasional\n",
            "--------------------\n",
            "input: tirumph\n",
            "target: triumph\n",
            "pred: triumph\n",
            "--------------------\n",
            "input: triam\n",
            "target: triumph\n",
            "pred: trim\n",
            "--------------------\n",
            "input: unforgatealbe\n",
            "target: unforgettable\n",
            "pred: unountaclete\n",
            "--------------------\n",
            "input: unforgattable\n",
            "target: unforgettable\n",
            "pred: unfortunate\n",
            "--------------------\n",
            "input: vesiable\n",
            "target: visible\n",
            "pred: vesible\n",
            "--------------------\n",
            "input: visable\n",
            "target: visible\n",
            "pred: visible\n",
            "--------------------\n",
            "BLEU-4 score:0.3365518013413313\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}